# Marketing Factory Refactor: Complete Vision & Decisions

<document_meta>
created: 2026-02-07
purpose: Captures every concept, decision, and architectural pattern discussed during the refactor planning session. This is the "why" document — the refactor plan (.refactor-plan.md) is the "what" document.
</document_meta>

---

## 1. What We're Building

The Marketing Factory is a system where Claude CLI operates as an AI-powered agency. It researches brands, develops marketing strategies, and builds complete autonomous marketing systems for clients — including n8n workflow automation, analytics dashboards, customer-facing websites, and dual-database infrastructure (Neo4j + Pinecone).

The factory has two layers:
- **Layer 1 (The Factory):** Claude agents that analyze client brands and generate complete, customized marketing systems
- **Layer 2 (Client Systems):** The autonomous marketing platforms spawned for each client, running on n8n with 6 runtime AI agents making daily optimization decisions

---

## 2. The Problem We Identified

The system was designed by web-based Claude, which wrote specifications as if handing them off to a junior engineer who needs to copy-paste. This produced:

- **~22,400 lines** of specification across 35 files
- **~900 code blocks** containing literal implementations (exact TypeScript components, exact Cypher queries, exact n8n node JSON, exact Python scripts)
- **Massive duplication** — the same information repeated across spec.md (4,368 lines), system-specs, agent files, and commands
- **No inter-agent collaboration** — agents run in isolation, passing files forward with no feedback or shared reasoning
- **Build-only agents** — agents can create systems but can't modify, debug, or optimize them afterward
- **No system state tracking** — after initial build, there's no record of what exists, what's changed, or what depends on what

### The Core Contradiction

`overall_explanation.md` states the philosophy perfectly:

> "Agent-driven, not script-driven. Agents are given a role, goal, context, and constraints. They figure out HOW to accomplish their goal. We don't prescribe exact implementations."

But the actual files contradict this. They tell agents exactly what to build, exactly what code to write, exactly what file structures to create. This removes the agent's ability to make intelligent decisions — which is the entire point of using an agentic system.

### The Token Problem

Every time an agent runs, it ingests context. With the current system:
- An agent might need to read a 1,453-line spec file to extract 200 lines of relevant principles
- 5 agents reading spec.md during `/initialize-client` = ~70,000 tokens just on context loading
- Most of those tokens are irrelevant code blocks the agent doesn't need — it can write better code itself with just the principles

---

## 3. Context Engineering: The Central Concept

The emerging discipline of **context engineering** is the key to this refactor. The quality of an agent's output is bounded by the quality of the context it receives, not just the quality of the prompt. This means:

- **Selective context loading** — agents read only what's relevant to their domain, not everything
- **Context distillation** — an orchestrator compresses what matters from upstream agents and routes it to downstream agents
- **Structured markup** — semantic XML tags let agents instantly categorize and prioritize information instead of parsing unstructured prose
- **File system as extended memory** — offload context to files, read only what you need, write reasoning for other agents to consume later

### The Hierarchy of Context

```
SYSTEM.md (~200 lines)          ← Every agent reads this. Always.
  ↓
Domain spec (~200 lines)        ← Agent reads 1-2 specs relevant to its work
  ↓
Client context (~variable)      ← brand-config.json, manifest, build context
  ↓
Upstream agent reasoning        ← From build context scratchpad
```

An agent's total context load drops from potentially thousands of lines to ~500-1,500 lines of highly relevant, well-structured information.

---

## 4. The Layered Architecture

### Layer 1: SYSTEM.md (Global Context)

A single ~150-200 line document that every agent reads. It provides:
- What the factory builds (one paragraph)
- How components connect (n8n ↔ databases ↔ dashboard ↔ website)
- Data flow overview
- Shared conventions (brand_id isolation, directory structure, config patterns)
- Database philosophy (Neo4j for structured facts, Pinecone for semantic memory)
- Agent category summary

This replaces the need for agents to read spec.md (4,368 lines) or multiple large system-specs for basic system understanding.

### Layer 2: Focused System-Specs (~150-300 lines each)

8 focused specs, down from 21 files + spec.md. Each describes principles, patterns, and constraints — never literal implementations. An agent reads only the 1-2 specs relevant to its domain.

**The 8 specs:**
1. `n8n-system.md` — Workflow purposes, triggers, data flows, agent roles
2. `dashboard-architecture.md` — Progressive disclosure philosophy, feature matrix, design principles
3. `website-patterns.md` — Conversion patterns, business model routing, integration points (merged from 2 files)
4. `database-design.md` — Schema design, node/relationship types, when-to-use-which-db (merged from 3 files)
5. `content-profiling.md` — What to extract, taxonomy framework, semantic description concept
6. `integration-patterns.md` — Data flow between components, interface contracts
7. `agent-collaboration.md` — Handoff patterns, dependency management, scratchpad protocol
8. `credentials-and-setup.md` — Setup guidance consolidated from 10 small files

**Total: ~1,500 lines** (down from ~13,300)

### Layer 3: Agent Definitions

13 agents + 1 new orchestrator, each 50-300 lines with structured XML sections supporting multiple operating modes (build, modify, debug, optimize).

### Layer 4: Client-Level Context

Per-client files that track state and enable collaboration:
- `.manifest.md` — Living system state (what exists, what changed, dependencies)
- `.build-context.md` — Shared reasoning scratchpad (decisions, discoveries, cross-agent requests)
- `brand-config.json` — Master configuration

---

## 5. Structured Markup Convention

Anthropic recommends organizing prompts into distinct sections with semantic tags. We're applying this principle across every file type, with tags adapted to each file's purpose.

### Why This Matters

When Claude reads a file, unstructured prose forces it to figure out "what kind of information is this?" Structured sections with semantic tags let the model instantly categorize and prioritize. An agent seeing `<constraints>` knows these are hard rules. An agent seeing `<reference_examples>` knows these are illustrations, not mandates.

### File Type → Section Structure

**System-specs:**
```
<purpose> — What this component does and why (2-3 sentences)
<design_principles> — Non-negotiable architectural decisions with rationale
<patterns> — Reusable patterns described in natural language
<interfaces> — Inputs, outputs, APIs — the contract with other components
<constraints> — Hard limits and rules
<quality_criteria> — How to evaluate the implementation
<reference_examples> — Optional: 1-2 brief illustrations (not full implementations)
```

**Agent definitions:**
```
<role> — Identity and domain ownership (3-5 sentences, second person)
<system_context> — Which files to read (SYSTEM.md, relevant spec, client files)
<capabilities> — What this agent can do: build, modify, debug, optimize
<build_mode> — How to approach building from scratch
<modify_mode> — How to approach changes to existing systems
<interfaces> — What it receives from upstream, what it produces for downstream
<output_standards> — Quality criteria for outputs
<collaboration> — How to communicate via build context scratchpad
```

**Commands:**
```
<purpose> — What the command accomplishes
<input> — Arguments and how to parse them
<prerequisites> — What must exist before running
<orchestration> — Agent invocation sequence and context flow
<context_flow> — How information flows between phases
<error_handling> — What to do when things fail
<completion> — What to show the user when done
```

**Build context scratchpad:**
```
<build_meta> — Client name, timestamp, mode, trigger
<decisions> — Key decisions by each agent with reasoning
<discoveries> — Unexpected findings
<cross_agent_requests> — Explicit requests from one agent to another
<open_questions> — Unresolved questions needing user input
<warnings> — Risks and concerns
```

**Client manifest:**
```
<system_state> — Component status, locations, versions
<configuration> — Key config values from brand-config.json
<change_log> — Chronological record of all changes with who/what/why
<dependency_map> — Which components depend on which artifacts
<known_issues> — Current problems or limitations
```

**Factory memory:**
```
<patterns_that_work> — Successful approaches tagged by business type
<patterns_to_avoid> — Failures and why they failed
<schema_evolution> — Database changes that should be incorporated into future builds
<client_feedback> — What clients said about the systems we built
```

---

## 6. Inter-Agent Collaboration

### The Problem

During `/initialize-client`, agents run sequentially but in isolation. Information only flows forward through output files. There's no feedback, no negotiation, no shared reasoning.

The strategist can't ask the brand-research agent about nuances. The creative-director can't tell the strategist to adjust platform allocation based on visual brand strength. The database-schema agent can't inform the n8n-architect about schema design decisions.

### The Solution: Build Context Scratchpad (Blackboard Architecture)

Every agent reads `.build-context.md` at the start of their phase and appends to it at the end. This is the **blackboard architecture pattern** — multiple agents read from and write to a shared surface.

**What agents write:**
- Key decisions and their reasoning (not just the decision, but WHY)
- Discoveries that weren't expected
- Warnings and risks
- Explicit requests for downstream agents

**What agents read:**
- Upstream decisions and reasoning (so they understand context, not just outputs)
- Requests directed at them from other agents
- Warnings about potential issues

**Example flow:**
```
[brand-research] → writes: "Very weak social media presence — competitor opportunity"
[competitive-intel] → reads that, writes: "Confirmed. Gap found: nobody doing video content"
[strategist] → reads both, writes: "Increased Instagram allocation to 60% based on video gap"
[creative-director] → reads strategist's reasoning, writes: "REQUEST → dashboard-architect: highlight content performance by tone, this is the primary creative lever"
[dashboard-architect] → reads the request, adapts dashboard design accordingly
```

This is incredibly cheap (~500 tokens to read) and provides something no amount of spec-reading can: the **reasoning and judgment** of upstream agents.

### Context Distillation

Between phases, the orchestrator (or the command itself) reads the build context and constructs a **focused brief** for the next agent. Instead of the strategist reading raw 1,500-word research files, the orchestrator says:

> "Here's what matters from research: the brand is a wellness-focused acupuncture clinic, competitors are weak on video and social, and the brand-research agent flagged the website may be outdated. Full research is at these paths if you need detail."

This is context distillation — compressing what matters and routing it to who needs it.

---

## 7. Agents as a Persistent Team (Not Just Builders)

### The Shift

The current mental model: agents run once during build, then they're done.

The real usage pattern:
```
Day 1:   /initialize-client name=zen-med-clinic
Day 3:   "Add TikTok as a platform"
Day 10:  "ROAS is low on Facebook, investigate"
Day 15:  "Add a blog section to the website"
Day 30:  "Fix the weekly strategy report"
Day 45:  "New client, similar industry — learn from zen-med-clinic"
```

Every agent needs to understand the **current state** of a client system (not just the initial design), make **targeted changes** without rebuilding everything, know **what's changed** since initial build, and **reason about impact** on other components.

### Multi-Mode Agent Definitions

Every agent gets four operating modes:

- **Build Mode:** Create the component from scratch during initial client setup
- **Modify Mode:** Make targeted changes to existing implementations. Read the manifest first. Assess impact. Make surgical changes. Update manifest and build context.
- **Debug Mode:** Investigate and fix issues. Read logs, check configs, trace data flow problems across components.
- **Optimize Mode:** Improve based on performance data or feedback. Use actual client results to refine the component.

### The Client Manifest

Each client system gets a `.manifest.md` that tracks:
- **System state:** What's deployed, where, and what version
- **Change log:** Every modification with who made it, what changed, and why
- **Dependency map:** Which components depend on which artifacts (critical for safe modifications)
- **Known issues:** Current problems or limitations

When someone says "add a blog to the website," the orchestrator reads the manifest, understands what exists, checks the dependency map for impact, and routes the request to the right agents with the right context.

---

## 8. The Orchestrator Agent

A new agent that doesn't build anything itself. Its job is context engineering at runtime:

- **Analyze user requests** — Understand what's being asked and decompose into agent tasks
- **Route dynamically** — Determine which agents need to act and in what order
- **Distill context** — Between agent invocations, read the build context and construct focused briefs for the next agent
- **Monitor collaboration** — Watch for cross-agent requests in the build context and route them
- **Consult memory** — Check factory memory for relevant learnings from previous clients
- **Maintain state** — Update the manifest after all changes are complete

The orchestrator is the one agent that reads broadly. Every other agent reads narrowly (SYSTEM.md + their spec + client context). The orchestrator reads everything and decides what each agent needs to see.

---

## 9. Factory Memory (Cross-Client Learning)

After each client build, the system captures what worked and what didn't in `factory-memory/`:

- **Patterns that work:** "Instagram-heavy platform mix has worked well for local service businesses"
- **Patterns to avoid:** "Separate lead-scoring workflow adds complexity without value for Shopify clients"
- **Schema evolution:** "Added appointment-tracking nodes for service businesses after client #2 needed them"
- **Client feedback:** "Clients say the weekly report is too long — aim for 3-5 key points"

Agents consult factory memory during builds, so the factory gets smarter with each client. By client #5, the system genuinely knows what works for different business types.

---

## 10. New Commands

### /modify-client

Takes a natural language description of what to change. The orchestrator reads the manifest, determines which agents need to act, constructs focused briefs, runs them in dependency order, updates the manifest.

Example: `/modify-client name=zen-med-clinic "Add TikTok as a marketing platform"`
→ Orchestrator routes to: strategist (update brand-config) → n8n-architect (add TikTok data fetching) → dashboard-architect (add TikTok to platform comparison)

### /debug-client

Takes a problem description. The orchestrator reads the manifest, traces likely affected components, investigates, proposes a fix, optionally executes it.

Example: `/debug-client name=zen-med-clinic "Weekly strategy report isn't including lead quality data"`
→ Orchestrator routes to: n8n-architect (investigate weekly-strategy workflow) → possibly dashboard-architect (if the report data is missing from the API)

---

## 11. The Refactor by the Numbers

### Before (Current State)

| Category | Files | Lines | Code Blocks |
|----------|-------|-------|-------------|
| spec.md | 1 | 4,368 | 110 |
| System-specs (large) | 11 | ~12,850 | ~700 |
| System-specs (small) | 10 | ~460 | ~2 |
| Agent definitions | 13 | 4,280 | ~90 |
| Commands | 5 | ~2,500 | ~20 |
| **Total** | **40** | **~24,460** | **~920** |

### After (Target)

| Category | Files | Lines | Code Blocks |
|----------|-------|-------|-------------|
| SYSTEM.md | 1 | ~200 | 0 |
| System-specs (refactored) | 8 | ~1,500 | ~10-15 |
| Agent definitions (refactored) | 14 | ~2,500 | ~5-10 |
| Commands (refactored) | 7 | ~1,500 | 0 |
| Templates + factory memory | 6 | ~300 | 0 |
| **Total** | **36** | **~6,000** | **~15-25** |

**75% reduction in total lines.** Token cost per agent invocation drops from ~3,000-14,000 to ~500-1,500.

---

## 12. Key Concepts and Search Terms

For further reading on the patterns and principles underlying this refactor:

**Context Engineering**
- "context engineering LLM agents" — The discipline of managing what context an agent sees and when
- "context distillation" / "context compression" — Summarizing large contexts into focused briefs

**Multi-Agent Architecture**
- "blackboard architecture multi-agent" — The shared scratchpad pattern (from 1970s AI, newly relevant)
- "agentic orchestration patterns" — Sequential chains, fan-out/fan-in, hierarchical delegation
- "dynamic agent routing" / "intent-based routing" — Routing requests to the right agent based on analysis
- "agent handoff protocols" — Formalized inter-agent communication patterns

**Agent Memory**
- "stateful agents" / "persistent agent state" — Agents that maintain awareness across invocations
- "agent memory architecture" — Episodic (what happened), semantic (general knowledge), conversational (ongoing state)
- "event sourcing for agents" — Storing change history rather than just current state
- "memory-augmented agents" — Using persistent storage to enhance agent capabilities

**Agent Capabilities**
- "agent-as-a-tool" / "hierarchical agents" — Agents that invoke other agents
- "scratchpad prompting" / "chain of thought externalization" — Writing reasoning to files
- "reflection agents" / "self-critique agents" — Agents that review their own or others' output
- "tool-use planning" / "ReAct pattern" — Reasoning about what action to take next

**Frameworks and Protocols**
- "LangGraph" — Stateful multi-agent applications with cycles
- "CrewAI" — Role-based multi-agent collaboration
- "AutoGen" (Microsoft) — Multi-agent conversation framework
- "Claude agent SDK" / "Anthropic agent patterns"
- "Model Context Protocol (MCP)" — Anthropic's protocol for tool and data source access
- "OpenAI Swarm" — Lightweight agent handoff patterns

---

## 13. The Guiding Metaphor

If you hired a brilliant marketing automation architect, you wouldn't hand them 22,000 lines of exact code to copy. You'd hand them a system design document explaining the architecture, the patterns, the constraints, and the "why" — and trust them to build it.

That's what these agents are. They're the architects. The specs should be the brief, not the blueprint. The build context should be their team communication channel. The manifest should be their project management tool. The factory memory should be their institutional knowledge.

We're not building a template engine. We're building an intelligent team that gets better with every client.
